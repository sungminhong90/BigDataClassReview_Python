{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sect4. Multi-variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex01. Multi-variable linear regression\n",
    "### Predictin exam score\n",
    "regression using three inputs (x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "\n",
    "$$ H(x) = Wx + b $$\n",
    "$$ H(x1, x2, x3) = w1 x1 + w2 x2 + w3 x3 + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "$$ H(x1, x2, x3) = w1 x1 + w2 x2 + w3 x3 + b $$\n",
    "$$ cost(W,b) = \\frac{1}{m} \\sum^m_{i=1}(H(x1^{(i)}, x2^{(i)}, x3^{(i)} )-y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_2:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y  = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b  = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "print(hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1feceaf406e40278dea14b6aa2b6bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 62547.2890625 \n",
      "Prediction :\n",
      "[-75.96345  -78.27629  -83.83015  -90.80436  -56.976482]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 19614.837890625 \n",
      "Prediction :\n",
      "[21.697487 39.10213  31.826246 35.14237  32.553165]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 6157.78759765625 \n",
      "Prediction :\n",
      "[ 76.37489  104.817566  96.5782   105.65545   82.676956]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1939.7125244140625 \n",
      "Prediction :\n",
      "[106.9874  141.6088  132.83064 145.13327 110.73886]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 617.5654907226562 \n",
      "Prediction :\n",
      "[124.12685 162.2064  153.12724 167.23558 126.44912]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 203.13729858398438 \n",
      "Prediction :\n",
      "[133.72324 173.73782 164.49077 179.61    135.24416]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 73.23114776611328 \n",
      "Prediction :\n",
      "[139.09654 180.1934  170.85298 186.5381  140.1676 ]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 32.50749206542969 \n",
      "Prediction :\n",
      "[142.10548 183.8072  174.41512 190.41704 142.92351]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 19.737699508666992 \n",
      "Prediction :\n",
      "[143.79071 185.82999 176.40964 192.58882 144.46584]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 15.729873657226562 \n",
      "Prediction :\n",
      "[144.73486 186.96207 177.52652 193.8049  145.3288 ]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 13.247164726257324 \n",
      "Prediction :\n",
      "[146.06377 188.31447 178.98654 195.37894 146.31259]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 12.562139511108398 \n",
      "Prediction :\n",
      "[146.20279 188.21931 179.0293  195.4085  146.1889 ]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 11.913301467895508 \n",
      "Prediction :\n",
      "[146.3381  188.12671 179.07095 195.43723 146.06857]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 11.2986478805542 \n",
      "Prediction :\n",
      "[146.46979 188.03654 179.11147 195.46513 145.95143]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 10.71639347076416 \n",
      "Prediction :\n",
      "[146.59799 187.9488  179.15092 195.4923  145.83746]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 10.164846420288086 \n",
      "Prediction :\n",
      "[146.72278 187.8634  179.18935 195.51869 145.72656]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 9.642377853393555 \n",
      "Prediction :\n",
      "[146.84425 187.78029 179.22675 195.54437 145.61865]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 9.147439956665039 \n",
      "Prediction :\n",
      "[146.96246 187.69936 179.26315 195.5693  145.51361]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 8.678604125976562 \n",
      "Prediction :\n",
      "[147.07758 187.6206  179.29858 195.59357 145.41145]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 8.234492301940918 \n",
      "Prediction :\n",
      "[147.18959 187.54395 179.33308 195.61716 145.31201]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 7.8137712478637695 \n",
      "Prediction :\n",
      "[147.29865 187.46933 179.36667 195.64008 145.21526]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 7.415217399597168 \n",
      "Prediction :\n",
      "[147.4048  187.3967  179.39938 195.66235 145.12111]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 7.0377044677734375 \n",
      "Prediction :\n",
      "[147.50812 187.326   179.4312  195.68402 145.0295 ]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 6.680027008056641 \n",
      "Prediction :\n",
      "[147.6087  187.25717 179.46219 195.70505 144.94034]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 6.341263771057129 \n",
      "Prediction :\n",
      "[147.7066  187.1902  179.49237 195.72554 144.8536 ]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 6.020312786102295 \n",
      "Prediction :\n",
      "[147.80191 187.125   179.52174 195.74542 144.7692 ]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 5.716288089752197 \n",
      "Prediction :\n",
      "[147.89468 187.06155 179.55034 195.76476 144.68706]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 5.428299903869629 \n",
      "Prediction :\n",
      "[147.98499 186.99979 179.57817 195.78354 144.60715]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 5.1554765701293945 \n",
      "Prediction :\n",
      "[148.07289 186.93965 179.6053  195.8018  144.5294 ]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 4.8970112800598145 \n",
      "Prediction :\n",
      "[148.15845 186.8811  179.63167 195.81953 144.45372]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex02. Multi-variable matmul linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis using matrix\n",
    "$$ w1 x1 + w2 x2 + w3 x3 + ... + wn xn $$\n",
    "\n",
    "$$ [x{1} x{2} x{3}] \\times $$\n",
    "\\begin{bmatrix} w{1}\\ w{2}\\ w{3}\\end{bmatrix}\n",
    "\n",
    "\n",
    "$$ [x_1 w_1 + x_2 w_2 + x_3 w_3] $$\n",
    "\n",
    "$$H(X) = XW$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.], \n",
    "          [96., 98., 100.], \n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de709b37a284dd68ee27c3b448aa43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 126121.6015625 \n",
      "Prediction :\n",
      "[[-159.22546]\n",
      " [-197.2163 ]\n",
      " [-191.33363]\n",
      " [-208.02669]\n",
      " [-152.1618 ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 39541.20703125 \n",
      "Prediction :\n",
      "[[-20.541216]\n",
      " [-30.525648]\n",
      " [-27.091803]\n",
      " [-29.171347]\n",
      " [-25.018284]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 12402.84375 \n",
      "Prediction :\n",
      "[[57.10242 ]\n",
      " [62.798733]\n",
      " [64.861   ]\n",
      " [70.963066]\n",
      " [46.165253]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 3896.40625 \n",
      "Prediction :\n",
      "[[100.57165 ]\n",
      " [115.04803 ]\n",
      " [116.34181 ]\n",
      " [127.02448 ]\n",
      " [ 86.018845]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 1230.0838623046875 \n",
      "Prediction :\n",
      "[[124.90789]\n",
      " [144.3009 ]\n",
      " [145.16386]\n",
      " [158.41109]\n",
      " [108.33195]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 394.32940673828125 \n",
      "Prediction :\n",
      "[[138.53227]\n",
      " [160.67891]\n",
      " [161.30006]\n",
      " [175.98314]\n",
      " [120.82479]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 132.36009216308594 \n",
      "Prediction :\n",
      "[[146.15947]\n",
      " [169.84877]\n",
      " [170.33397]\n",
      " [185.82094]\n",
      " [127.81961]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 50.24210739135742 \n",
      "Prediction :\n",
      "[[150.42906]\n",
      " [174.98303]\n",
      " [175.39156]\n",
      " [191.32863]\n",
      " [131.7363 ]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 24.497879028320312 \n",
      "Prediction :\n",
      "[[152.8189 ]\n",
      " [177.85794]\n",
      " [178.22293]\n",
      " [194.41203]\n",
      " [133.92967]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 16.424102783203125 \n",
      "Prediction :\n",
      "[[154.15625]\n",
      " [179.46786]\n",
      " [179.80792]\n",
      " [196.13815]\n",
      " [135.15817]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 12.159124374389648 \n",
      "Prediction :\n",
      "[[155.73917]\n",
      " [181.59718]\n",
      " [181.78825]\n",
      " [198.30481]\n",
      " [136.83037]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 11.551898956298828 \n",
      "Prediction :\n",
      "[[155.61072]\n",
      " [181.68556]\n",
      " [181.74934]\n",
      " [198.27315]\n",
      " [136.94933]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 10.976578712463379 \n",
      "Prediction :\n",
      "[[155.48576]\n",
      " [181.7716 ]\n",
      " [181.7115 ]\n",
      " [198.2423 ]\n",
      " [137.06516]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 10.431528091430664 \n",
      "Prediction :\n",
      "[[155.36418]\n",
      " [181.8553 ]\n",
      " [181.6747 ]\n",
      " [198.2122 ]\n",
      " [137.17793]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 9.915063858032227 \n",
      "Prediction :\n",
      "[[155.2459 ]\n",
      " [181.93675]\n",
      " [181.63889]\n",
      " [198.18283]\n",
      " [137.28775]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 9.425736427307129 \n",
      "Prediction :\n",
      "[[155.13078]\n",
      " [182.01599]\n",
      " [181.60406]\n",
      " [198.15417]\n",
      " [137.39467]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 8.96211051940918 \n",
      "Prediction :\n",
      "[[155.01881]\n",
      " [182.09311]\n",
      " [181.57019]\n",
      " [198.12622]\n",
      " [137.49878]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 8.522844314575195 \n",
      "Prediction :\n",
      "[[154.90987]\n",
      " [182.16814]\n",
      " [181.53726]\n",
      " [198.09897]\n",
      " [137.60016]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 8.106585502624512 \n",
      "Prediction :\n",
      "[[154.80386]\n",
      " [182.24115]\n",
      " [181.50522]\n",
      " [198.07234]\n",
      " [137.69887]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 7.712207794189453 \n",
      "Prediction :\n",
      "[[154.70074]\n",
      " [182.3122 ]\n",
      " [181.47406]\n",
      " [198.04639]\n",
      " [137.79498]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 7.338504791259766 \n",
      "Prediction :\n",
      "[[154.60042]\n",
      " [182.3813 ]\n",
      " [181.44374]\n",
      " [198.02104]\n",
      " [137.88858]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 6.984408378601074 \n",
      "Prediction :\n",
      "[[154.50282]\n",
      " [182.44858]\n",
      " [181.41429]\n",
      " [197.99632]\n",
      " [137.97972]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 6.648866176605225 \n",
      "Prediction :\n",
      "[[154.40787]\n",
      " [182.514  ]\n",
      " [181.38562]\n",
      " [197.9722 ]\n",
      " [138.06848]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 6.3309125900268555 \n",
      "Prediction :\n",
      "[[154.31548]\n",
      " [182.57768]\n",
      " [181.35774]\n",
      " [197.94864]\n",
      " [138.15489]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 6.0295867919921875 \n",
      "Prediction :\n",
      "[[154.2256 ]\n",
      " [182.63965]\n",
      " [181.33066]\n",
      " [197.92566]\n",
      " [138.23907]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 5.744067192077637 \n",
      "Prediction :\n",
      "[[154.13815]\n",
      " [182.69992]\n",
      " [181.30429]\n",
      " [197.9032 ]\n",
      " [138.32101]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 5.473510265350342 \n",
      "Prediction :\n",
      "[[154.0531 ]\n",
      " [182.75859]\n",
      " [181.27867]\n",
      " [197.88133]\n",
      " [138.40083]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 5.2171173095703125 \n",
      "Prediction :\n",
      "[[153.97035]\n",
      " [182.81563]\n",
      " [181.25374]\n",
      " [197.85992]\n",
      " [138.47855]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 4.974080562591553 \n",
      "Prediction :\n",
      "[[153.88986]\n",
      " [182.87119]\n",
      " [181.2295 ]\n",
      " [197.83907]\n",
      " [138.55426]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 4.743807792663574 \n",
      "Prediction :\n",
      "[[153.81155]\n",
      " [182.9252 ]\n",
      " [181.20593]\n",
      " [197.81868]\n",
      " [138.62796]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex03. File input linear regression\n",
    "### Loading Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape : (25, 3), \tlen(x_data) : 25 \n",
      "x_data : \n",
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]]\n",
      "-------------------------\n",
      "y_data.shape : (25, 1)  \n",
      "y_data : \n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "xy = np.loadtxt('./data/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(\"x_data.shape : {}, \\tlen(x_data) : {} \\nx_data : \\n{}\".format(x_data.shape, len(x_data), x_data))\n",
    "print(\"-\"*25)\n",
    "print(\"y_data.shape : {}  \\ny_data : \\n{}\".format(y_data.shape, y_data))\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 20682.216796875 \n",
      "Prediction :\n",
      "[[15.3530855]\n",
      " [25.620491 ]\n",
      " [21.435873 ]\n",
      " [23.021599 ]\n",
      " [21.901628 ]\n",
      " [17.103834 ]\n",
      " [15.216542 ]\n",
      " [ 8.105922 ]\n",
      " [25.533789 ]\n",
      " [23.99665  ]\n",
      " [17.138174 ]\n",
      " [20.137476 ]\n",
      " [22.434807 ]\n",
      " [19.68472  ]\n",
      " [16.372953 ]\n",
      " [25.100708 ]\n",
      " [21.371382 ]\n",
      " [16.114529 ]\n",
      " [20.338524 ]\n",
      " [17.508432 ]\n",
      " [18.731852 ]\n",
      " [23.45593  ]\n",
      " [17.350943 ]\n",
      " [16.195797 ]\n",
      " [25.42364  ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 7661.43017578125 \n",
      "Prediction :\n",
      "[[68.32281 ]\n",
      " [89.28384 ]\n",
      " [84.165085]\n",
      " [91.338844]\n",
      " [70.45464 ]\n",
      " [52.900417]\n",
      " [66.35534 ]\n",
      " [46.018482]\n",
      " [85.03186 ]\n",
      " [79.10705 ]\n",
      " [66.40696 ]\n",
      " [68.71708 ]\n",
      " [87.24234 ]\n",
      " [73.55812 ]\n",
      " [67.74665 ]\n",
      " [89.70451 ]\n",
      " [72.67783 ]\n",
      " [77.48663 ]\n",
      " [82.12339 ]\n",
      " [72.79138 ]\n",
      " [78.69987 ]\n",
      " [83.181145]\n",
      " [74.525734]\n",
      " [69.60098 ]\n",
      " [91.40337 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 2847.277099609375 \n",
      "Prediction :\n",
      "[[100.53139 ]\n",
      " [127.994156]\n",
      " [122.30769 ]\n",
      " [132.87944 ]\n",
      " [ 99.9769  ]\n",
      " [ 74.66642 ]\n",
      " [ 97.45092 ]\n",
      " [ 69.07227 ]\n",
      " [121.20958 ]\n",
      " [112.61717 ]\n",
      " [ 96.36511 ]\n",
      " [ 98.255974]\n",
      " [126.64848 ]\n",
      " [106.315506]\n",
      " [ 98.984985]\n",
      " [128.98691 ]\n",
      " [103.874016]\n",
      " [114.80494 ]\n",
      " [119.69167 ]\n",
      " [106.406265]\n",
      " [115.164024]\n",
      " [119.4971  ]\n",
      " [109.29144 ]\n",
      " [102.07391 ]\n",
      " [131.52219 ]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1067.34716796875 \n",
      "Prediction :\n",
      "[[120.11607 ]\n",
      " [151.53174 ]\n",
      " [145.50034 ]\n",
      " [158.1384  ]\n",
      " [117.92744 ]\n",
      " [ 87.90109 ]\n",
      " [116.359146]\n",
      " [ 83.091156]\n",
      " [143.20728 ]\n",
      " [132.99318 ]\n",
      " [114.581375]\n",
      " [116.21712 ]\n",
      " [150.60925 ]\n",
      " [126.23322 ]\n",
      " [117.97998 ]\n",
      " [152.87253 ]\n",
      " [122.84208 ]\n",
      " [137.49727 ]\n",
      " [142.53499 ]\n",
      " [126.845825]\n",
      " [137.33658 ]\n",
      " [141.579   ]\n",
      " [130.43123 ]\n",
      " [121.818924]\n",
      " [155.91618 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 409.25250244140625 \n",
      "Prediction :\n",
      "[[132.02481]\n",
      " [165.84348]\n",
      " [159.60263]\n",
      " [173.49728]\n",
      " [128.84175]\n",
      " [ 95.94826]\n",
      " [127.85686]\n",
      " [ 91.61634]\n",
      " [156.5828 ]\n",
      " [145.38297]\n",
      " [125.65794]\n",
      " [127.13838]\n",
      " [165.17842]\n",
      " [138.34377]\n",
      " [129.53036]\n",
      " [167.3961 ]\n",
      " [134.37482]\n",
      " [151.29623]\n",
      " [156.42476]\n",
      " [139.27408]\n",
      " [150.8191 ]\n",
      " [155.00583]\n",
      " [143.28575]\n",
      " [133.8247 ]\n",
      " [170.74866]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 165.9315185546875 \n",
      "Prediction :\n",
      "[[139.26611 ]\n",
      " [174.54541 ]\n",
      " [168.1775  ]\n",
      " [182.83641 ]\n",
      " [135.47769 ]\n",
      " [100.841156]\n",
      " [134.84854 ]\n",
      " [ 96.80106 ]\n",
      " [164.71556 ]\n",
      " [152.9167  ]\n",
      " [132.3932  ]\n",
      " [133.77902 ]\n",
      " [174.03699 ]\n",
      " [145.7071  ]\n",
      " [136.55403 ]\n",
      " [176.22707 ]\n",
      " [141.38647 ]\n",
      " [159.68756 ]\n",
      " [164.87029 ]\n",
      " [146.83105 ]\n",
      " [159.01762 ]\n",
      " [163.16992 ]\n",
      " [151.10239 ]\n",
      " [141.12462 ]\n",
      " [179.76724 ]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 75.96328735351562 \n",
      "Prediction :\n",
      "[[143.66942 ]\n",
      " [179.83632 ]\n",
      " [173.39145 ]\n",
      " [188.51521 ]\n",
      " [139.51218 ]\n",
      " [103.816086]\n",
      " [139.10039 ]\n",
      " [ 99.954605]\n",
      " [169.66049 ]\n",
      " [157.49773 ]\n",
      " [136.48875 ]\n",
      " [137.81685 ]\n",
      " [179.42325 ]\n",
      " [150.18394 ]\n",
      " [140.82524 ]\n",
      " [181.59665 ]\n",
      " [145.64911 ]\n",
      " [164.79079 ]\n",
      " [170.00548 ]\n",
      " [151.42606 ]\n",
      " [164.0032  ]\n",
      " [168.13403 ]\n",
      " [155.85576 ]\n",
      " [145.56313 ]\n",
      " [185.25069 ]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 42.6942138671875 \n",
      "Prediction :\n",
      "[[146.34705]\n",
      " [183.05315]\n",
      " [176.56174]\n",
      " [191.96834]\n",
      " [141.96478]\n",
      " [105.6248 ]\n",
      " [141.68622]\n",
      " [101.87311]\n",
      " [172.66702]\n",
      " [160.28333]\n",
      " [138.9792 ]\n",
      " [140.27197]\n",
      " [182.69812]\n",
      " [152.90562]\n",
      " [143.42278]\n",
      " [184.86151]\n",
      " [148.24016]\n",
      " [167.89465]\n",
      " [173.12775]\n",
      " [154.22   ]\n",
      " [167.03514]\n",
      " [171.15234]\n",
      " [158.74648]\n",
      " [148.26175]\n",
      " [188.58456]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 30.388269424438477 \n",
      "Prediction :\n",
      "[[147.9754 ]\n",
      " [185.0088 ]\n",
      " [178.48941]\n",
      " [194.06815]\n",
      " [143.45558]\n",
      " [106.7244 ]\n",
      " [143.25905]\n",
      " [103.04062]\n",
      " [174.49492]\n",
      " [161.97722]\n",
      " [140.49365]\n",
      " [141.7648 ]\n",
      " [184.68921]\n",
      " [154.56006]\n",
      " [145.00267]\n",
      " [186.84659]\n",
      " [149.81482]\n",
      " [169.7828 ]\n",
      " [175.02612]\n",
      " [155.91881]\n",
      " [168.87918]\n",
      " [172.98755]\n",
      " [160.50461]\n",
      " [149.90242]\n",
      " [190.61142]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 25.833059310913086 \n",
      "Prediction :\n",
      "[[148.96571 ]\n",
      " [186.19762 ]\n",
      " [179.66148 ]\n",
      " [195.34505 ]\n",
      " [144.36153 ]\n",
      " [107.392815]\n",
      " [144.21591 ]\n",
      " [103.7515  ]\n",
      " [175.60614 ]\n",
      " [163.00731 ]\n",
      " [141.41467 ]\n",
      " [142.67245 ]\n",
      " [185.89964 ]\n",
      " [155.56558 ]\n",
      " [145.96376 ]\n",
      " [188.0535  ]\n",
      " [150.77145 ]\n",
      " [170.93175 ]\n",
      " [176.18025 ]\n",
      " [156.95172 ]\n",
      " [170.00089 ]\n",
      " [174.10332 ]\n",
      " [161.57405 ]\n",
      " [150.89981 ]\n",
      " [191.8435  ]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 22.404691696166992 \n",
      "Prediction :\n",
      "[[150.5473  ]\n",
      " [187.96669 ]\n",
      " [181.46933 ]\n",
      " [197.35283 ]\n",
      " [145.64584 ]\n",
      " [108.3843  ]\n",
      " [145.81367 ]\n",
      " [105.072525]\n",
      " [177.2764  ]\n",
      " [164.62859 ]\n",
      " [142.87476 ]\n",
      " [144.06886 ]\n",
      " [187.72502 ]\n",
      " [157.01823 ]\n",
      " [147.55348 ]\n",
      " [189.89801 ]\n",
      " [152.06667 ]\n",
      " [172.90443 ]\n",
      " [177.93462 ]\n",
      " [158.5428  ]\n",
      " [171.84175 ]\n",
      " [175.80943 ]\n",
      " [163.32925 ]\n",
      " [152.39713 ]\n",
      " [193.67918 ]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 21.608549118041992 \n",
      "Prediction :\n",
      "[[150.59721]\n",
      " [187.88435]\n",
      " [181.45818]\n",
      " [197.38214]\n",
      " [145.51343]\n",
      " [108.33407]\n",
      " [145.9373 ]\n",
      " [105.31051]\n",
      " [177.21715]\n",
      " [164.6527 ]\n",
      " [142.9088 ]\n",
      " [144.05554]\n",
      " [187.66827]\n",
      " [156.90184]\n",
      " [147.661  ]\n",
      " [189.86725]\n",
      " [151.86115]\n",
      " [173.11206]\n",
      " [177.8958 ]\n",
      " [158.53104]\n",
      " [171.9515 ]\n",
      " [175.78192]\n",
      " [163.43411]\n",
      " [152.3436 ]\n",
      " [193.59651]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 20.852519989013672 \n",
      "Prediction :\n",
      "[[150.64642 ]\n",
      " [187.80383 ]\n",
      " [181.44751 ]\n",
      " [197.41072 ]\n",
      " [145.38411 ]\n",
      " [108.284454]\n",
      " [146.05771 ]\n",
      " [105.54236 ]\n",
      " [177.15863 ]\n",
      " [164.67493 ]\n",
      " [142.94185 ]\n",
      " [144.04193 ]\n",
      " [187.61337 ]\n",
      " [156.78902 ]\n",
      " [147.76556 ]\n",
      " [189.83684 ]\n",
      " [151.66142 ]\n",
      " [173.31442 ]\n",
      " [177.85858 ]\n",
      " [158.52017 ]\n",
      " [172.05836 ]\n",
      " [175.75467 ]\n",
      " [163.53635 ]\n",
      " [152.29248 ]\n",
      " [193.5159  ]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 20.134536743164062 \n",
      "Prediction :\n",
      "[[150.69493]\n",
      " [187.7251 ]\n",
      " [181.43735]\n",
      " [197.43864]\n",
      " [145.25783]\n",
      " [108.2355 ]\n",
      " [146.17506]\n",
      " [105.76824]\n",
      " [177.1009 ]\n",
      " [164.69536]\n",
      " [142.974  ]\n",
      " [144.02812]\n",
      " [187.56035]\n",
      " [156.67967]\n",
      " [147.8673 ]\n",
      " [189.80682]\n",
      " [151.46732]\n",
      " [173.51172]\n",
      " [177.8229 ]\n",
      " [158.51016]\n",
      " [172.16245]\n",
      " [175.72774]\n",
      " [163.63603]\n",
      " [152.2437 ]\n",
      " [193.43733]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 19.452678680419922 \n",
      "Prediction :\n",
      "[[150.7427 ]\n",
      " [187.64812]\n",
      " [181.42767]\n",
      " [197.46588]\n",
      " [145.13452]\n",
      " [108.18718]\n",
      " [146.28938]\n",
      " [105.9883 ]\n",
      " [177.04396]\n",
      " [164.71414]\n",
      " [143.00525]\n",
      " [144.01411]\n",
      " [187.50906]\n",
      " [156.57368]\n",
      " [147.96626]\n",
      " [189.77722]\n",
      " [151.27867]\n",
      " [173.70403]\n",
      " [177.7887 ]\n",
      " [158.50098]\n",
      " [172.26376]\n",
      " [175.7011 ]\n",
      " [163.73323]\n",
      " [152.19711]\n",
      " [193.36072]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 18.805025100708008 \n",
      "Prediction :\n",
      "[[150.78976]\n",
      " [187.57285]\n",
      " [181.41844]\n",
      " [197.49246]\n",
      " [145.0141 ]\n",
      " [108.13951]\n",
      " [146.40079]\n",
      " [106.20271]\n",
      " [176.9878 ]\n",
      " [164.73131]\n",
      " [143.03561]\n",
      " [143.99994]\n",
      " [187.45949]\n",
      " [156.47093]\n",
      " [148.06253]\n",
      " [189.74799]\n",
      " [151.09532]\n",
      " [173.89148]\n",
      " [177.75589]\n",
      " [158.49257]\n",
      " [172.36243]\n",
      " [175.67476]\n",
      " [163.82802]\n",
      " [152.15263]\n",
      " [193.28601]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 18.18986701965332 \n",
      "Prediction :\n",
      "[[150.8361  ]\n",
      " [187.49925 ]\n",
      " [181.40965 ]\n",
      " [197.51842 ]\n",
      " [144.8965  ]\n",
      " [108.092514]\n",
      " [146.50934 ]\n",
      " [106.411606]\n",
      " [176.93243 ]\n",
      " [164.74701 ]\n",
      " [143.06517 ]\n",
      " [143.98563 ]\n",
      " [187.41156 ]\n",
      " [156.37132 ]\n",
      " [148.1562  ]\n",
      " [189.7192  ]\n",
      " [150.9171  ]\n",
      " [174.07423 ]\n",
      " [177.72444 ]\n",
      " [158.48488 ]\n",
      " [172.45853 ]\n",
      " [175.64876 ]\n",
      " [163.92044 ]\n",
      " [152.11018 ]\n",
      " [193.21321 ]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 17.605545043945312 \n",
      "Prediction :\n",
      "[[150.88173 ]\n",
      " [187.42732 ]\n",
      " [181.40128 ]\n",
      " [197.54373 ]\n",
      " [144.7817  ]\n",
      " [108.04619 ]\n",
      " [146.6151  ]\n",
      " [106.615135]\n",
      " [176.87787 ]\n",
      " [164.76128 ]\n",
      " [143.09387 ]\n",
      " [143.9712  ]\n",
      " [187.36522 ]\n",
      " [156.27475 ]\n",
      " [148.24733 ]\n",
      " [189.6908  ]\n",
      " [150.74385 ]\n",
      " [174.25238 ]\n",
      " [177.6943  ]\n",
      " [158.47789 ]\n",
      " [172.55211 ]\n",
      " [175.6231  ]\n",
      " [164.01056 ]\n",
      " [152.06966 ]\n",
      " [193.1422  ]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 17.050474166870117 \n",
      "Prediction :\n",
      "[[150.92662]\n",
      " [187.357  ]\n",
      " [181.3933 ]\n",
      " [197.56844]\n",
      " [144.66959]\n",
      " [108.00051]\n",
      " [146.71815]\n",
      " [106.81344]\n",
      " [176.82411]\n",
      " [164.77422]\n",
      " [143.1218 ]\n",
      " [143.95668]\n",
      " [187.32039]\n",
      " [156.18112]\n",
      " [148.33598]\n",
      " [189.6628 ]\n",
      " [150.57544]\n",
      " [174.42604]\n",
      " [177.66539]\n",
      " [158.47154]\n",
      " [172.64323]\n",
      " [175.59776]\n",
      " [164.09843]\n",
      " [152.03099]\n",
      " [193.07298]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 16.523147583007812 \n",
      "Prediction :\n",
      "[[150.9708 ]\n",
      " [187.28824]\n",
      " [181.38571]\n",
      " [197.59256]\n",
      " [144.56012]\n",
      " [107.95555]\n",
      " [146.81859]\n",
      " [107.00667]\n",
      " [176.7712 ]\n",
      " [164.78589]\n",
      " [143.14893]\n",
      " [143.94211]\n",
      " [187.27704]\n",
      " [156.0903 ]\n",
      " [148.42226]\n",
      " [189.63524]\n",
      " [150.41173]\n",
      " [174.59534]\n",
      " [177.63766]\n",
      " [158.46582]\n",
      " [172.732  ]\n",
      " [175.57275]\n",
      " [164.18413]\n",
      " [151.99405]\n",
      " [193.0055 ]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 16.02218246459961 \n",
      "Prediction :\n",
      "[[151.01425]\n",
      " [187.22104]\n",
      " [181.37845]\n",
      " [197.61606]\n",
      " [144.45323]\n",
      " [107.91125]\n",
      " [146.91643]\n",
      " [107.19492]\n",
      " [176.71906]\n",
      " [164.79636]\n",
      " [143.17532]\n",
      " [143.92747]\n",
      " [187.2351 ]\n",
      " [156.00223]\n",
      " [148.5062 ]\n",
      " [189.60808]\n",
      " [150.25253]\n",
      " [174.76038]\n",
      " [177.61105]\n",
      " [158.46065]\n",
      " [172.81842]\n",
      " [175.5481 ]\n",
      " [164.26767]\n",
      " [151.95882]\n",
      " [192.93967]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 15.546241760253906 \n",
      "Prediction :\n",
      "[[151.05699 ]\n",
      " [187.15535 ]\n",
      " [181.37157 ]\n",
      " [197.63904 ]\n",
      " [144.34889 ]\n",
      " [107.86764 ]\n",
      " [147.0118  ]\n",
      " [107.378365]\n",
      " [176.66776 ]\n",
      " [164.80574 ]\n",
      " [143.20099 ]\n",
      " [143.91283 ]\n",
      " [187.19453 ]\n",
      " [155.91682 ]\n",
      " [148.58789 ]\n",
      " [189.58134 ]\n",
      " [150.0978  ]\n",
      " [174.92126 ]\n",
      " [177.58557 ]\n",
      " [158.45604 ]\n",
      " [172.9026  ]\n",
      " [175.52379 ]\n",
      " [164.34915 ]\n",
      " [151.92519 ]\n",
      " [192.87553 ]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 15.094013214111328 \n",
      "Prediction :\n",
      "[[151.09898]\n",
      " [187.09114]\n",
      " [181.36497]\n",
      " [197.66142]\n",
      " [144.24698]\n",
      " [107.82471]\n",
      " [147.1047 ]\n",
      " [107.55711]\n",
      " [176.61723]\n",
      " [164.81404]\n",
      " [143.22592]\n",
      " [143.89812]\n",
      " [187.15527]\n",
      " [155.83397]\n",
      " [148.66736]\n",
      " [189.55501]\n",
      " [149.9473 ]\n",
      " [175.0781 ]\n",
      " [177.56108]\n",
      " [158.45193]\n",
      " [172.98457]\n",
      " [175.4998 ]\n",
      " [164.42857]\n",
      " [151.89307]\n",
      " [192.81294]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 14.664336204528809 \n",
      "Prediction :\n",
      "[[151.14027 ]\n",
      " [187.02838 ]\n",
      " [181.35873 ]\n",
      " [197.68329 ]\n",
      " [144.1475  ]\n",
      " [107.78246 ]\n",
      " [147.19525 ]\n",
      " [107.731285]\n",
      " [176.56755 ]\n",
      " [164.82135 ]\n",
      " [143.25018 ]\n",
      " [143.88345 ]\n",
      " [187.11731 ]\n",
      " [155.7536  ]\n",
      " [148.7447  ]\n",
      " [189.52908 ]\n",
      " [149.80098 ]\n",
      " [175.23099 ]\n",
      " [177.53763 ]\n",
      " [158.44832 ]\n",
      " [173.06445 ]\n",
      " [175.4762  ]\n",
      " [164.50604 ]\n",
      " [151.86243 ]\n",
      " [192.75195 ]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 14.256036758422852 \n",
      "Prediction :\n",
      "[[151.18088]\n",
      " [186.96709]\n",
      " [181.3528 ]\n",
      " [197.7046 ]\n",
      " [144.0504 ]\n",
      " [107.74088]\n",
      " [147.28351]\n",
      " [107.90101]\n",
      " [176.51869]\n",
      " [164.82774]\n",
      " [143.2738 ]\n",
      " [143.8688 ]\n",
      " [187.08058]\n",
      " [155.67564]\n",
      " [148.81999]\n",
      " [189.50362]\n",
      " [149.6587 ]\n",
      " [175.38008]\n",
      " [177.51512]\n",
      " [158.44516]\n",
      " [173.14223]\n",
      " [175.45296]\n",
      " [164.58159]\n",
      " [151.83322]\n",
      " [192.69249]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 13.868062973022461 \n",
      "Prediction :\n",
      "[[151.22076]\n",
      " [186.90715]\n",
      " [181.34712]\n",
      " [197.72545]\n",
      " [143.95558]\n",
      " [107.70002]\n",
      " [147.3695 ]\n",
      " [108.06641]\n",
      " [176.47064]\n",
      " [164.83324]\n",
      " [143.29677]\n",
      " [143.8542 ]\n",
      " [187.04503]\n",
      " [155.60002]\n",
      " [148.89326]\n",
      " [189.47855]\n",
      " [149.52034]\n",
      " [175.5254 ]\n",
      " [177.49355]\n",
      " [158.44243]\n",
      " [173.218  ]\n",
      " [175.43004]\n",
      " [164.65526]\n",
      " [151.80533]\n",
      " [192.6345 ]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 13.499359130859375 \n",
      "Prediction :\n",
      "[[151.25993]\n",
      " [186.84859]\n",
      " [181.34172]\n",
      " [197.74574]\n",
      " [143.86302]\n",
      " [107.65982]\n",
      " [147.45331]\n",
      " [108.22757]\n",
      " [176.4234 ]\n",
      " [164.83794]\n",
      " [143.31908]\n",
      " [143.83963]\n",
      " [187.0106 ]\n",
      " [155.52663]\n",
      " [148.96458]\n",
      " [189.4539 ]\n",
      " [149.38577]\n",
      " [175.66707]\n",
      " [177.47282]\n",
      " [158.4401 ]\n",
      " [173.29181]\n",
      " [175.40749]\n",
      " [164.7271 ]\n",
      " [151.7787 ]\n",
      " [192.57796]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 13.14897346496582 \n",
      "Prediction :\n",
      "[[151.29842]\n",
      " [186.79137]\n",
      " [181.3366 ]\n",
      " [197.76558]\n",
      " [143.77266]\n",
      " [107.6203 ]\n",
      " [147.53499]\n",
      " [108.38463]\n",
      " [176.37695]\n",
      " [164.84184]\n",
      " [143.3408 ]\n",
      " [143.82512]\n",
      " [186.97731]\n",
      " [155.45543]\n",
      " [149.03398]\n",
      " [189.42966]\n",
      " [149.25491]\n",
      " [175.80522]\n",
      " [177.45297]\n",
      " [158.43816]\n",
      " [173.3637 ]\n",
      " [175.3853 ]\n",
      " [164.79715]\n",
      " [151.75331]\n",
      " [192.52284]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 12.816009521484375 \n",
      "Prediction :\n",
      "[[151.33623 ]\n",
      " [186.73544 ]\n",
      " [181.33171 ]\n",
      " [197.78491 ]\n",
      " [143.68443 ]\n",
      " [107.58144 ]\n",
      " [147.61458 ]\n",
      " [108.537674]\n",
      " [176.33131 ]\n",
      " [164.84502 ]\n",
      " [143.36192 ]\n",
      " [143.81067 ]\n",
      " [186.94508 ]\n",
      " [155.38634 ]\n",
      " [149.10153 ]\n",
      " [189.40584 ]\n",
      " [149.12762 ]\n",
      " [175.93987 ]\n",
      " [177.43391 ]\n",
      " [158.43654 ]\n",
      " [173.43373 ]\n",
      " [175.36345 ]\n",
      " [164.86543 ]\n",
      " [151.7291  ]\n",
      " [192.4691  ]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 12.499527931213379 \n",
      "Prediction :\n",
      "[[151.37332]\n",
      " [186.6808 ]\n",
      " [181.32706]\n",
      " [197.80377]\n",
      " [143.59833]\n",
      " [107.54326]\n",
      " [147.69214]\n",
      " [108.68682]\n",
      " [176.28647]\n",
      " [164.8475 ]\n",
      " [143.38248]\n",
      " [143.79631]\n",
      " [186.91385]\n",
      " [155.31927]\n",
      " [149.16728]\n",
      " [189.38242]\n",
      " [149.00381]\n",
      " [176.07117]\n",
      " [177.41562]\n",
      " [158.43527]\n",
      " [173.50192]\n",
      " [175.34198]\n",
      " [164.93204]\n",
      " [151.70596]\n",
      " [192.41669]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131fc5d7a3c7460dbfdb0ee2898ee5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \tCost : 20682.216796875 \n",
      "Step : 1 \tCost : 7661.43017578125 \n",
      "Step : 2 \tCost : 2847.277099609375 \n",
      "Step : 3 \tCost : 1067.34716796875 \n",
      "Step : 4 \tCost : 409.25250244140625 \n",
      "Step : 5 \tCost : 165.9315185546875 \n",
      "Step : 6 \tCost : 75.96328735351562 \n",
      "Step : 7 \tCost : 42.6942138671875 \n",
      "Step : 8 \tCost : 30.388269424438477 \n",
      "Step : 9 \tCost : 25.833059310913086 \n",
      "Step : 100 \tCost : 22.404691696166992 \n",
      "Step : 200 \tCost : 21.608549118041992 \n",
      "Step : 300 \tCost : 20.852519989013672 \n",
      "Step : 400 \tCost : 20.134536743164062 \n",
      "Step : 500 \tCost : 19.452678680419922 \n",
      "Step : 600 \tCost : 18.805025100708008 \n",
      "Step : 700 \tCost : 18.18986701965332 \n",
      "Step : 800 \tCost : 17.605545043945312 \n",
      "Step : 900 \tCost : 17.050474166870117 \n",
      "Step : 1000 \tCost : 16.523147583007812 \n",
      "Step : 1100 \tCost : 16.02218246459961 \n",
      "Step : 1200 \tCost : 15.546241760253906 \n",
      "Step : 1300 \tCost : 15.094013214111328 \n",
      "Step : 1400 \tCost : 14.664336204528809 \n",
      "Step : 1500 \tCost : 14.256036758422852 \n",
      "Step : 1600 \tCost : 13.868062973022461 \n",
      "Step : 1700 \tCost : 13.499359130859375 \n",
      "Step : 1800 \tCost : 13.14897346496582 \n",
      "Step : 1900 \tCost : 12.816009521484375 \n",
      "Step : 2000 \tCost : 12.499527931213379 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        # print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "        print(\"Step : {} \\tCost : {} \".format(step, cost_val))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[194.89838]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score\n",
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[165.07944]\n",
      " [176.52182]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score many\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex04. TF reader linear regression 5\n",
    "- 참조 : https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 21:27:03.638805 15184 deprecation.py:323] From <ipython-input-12-7550bf96b580>:6: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 21:27:03.697765 15184 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 21:27:03.706760 15184 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0911 21:27:03.725748 15184 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 21:27:03.735743 15184 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 21:27:03.770724 15184 deprecation.py:323] From <ipython-input-12-7550bf96b580>:8: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "W0911 21:27:03.809702 15184 deprecation.py:323] From <ipython-input-12-7550bf96b580>:18: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['./data/data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the decoded result.\n",
    "# Convert CSV records to tensors. Each column maps to one tensor.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 21:27:13.647078 15184 deprecation.py:323] From <ipython-input-13-a0a2b752713a>:8: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62269294e3024498a3983e80567ae018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 30978.400390625 \n",
      "Prediction :\n",
      "[[-10.5520935]\n",
      " [-18.421577 ]\n",
      " [-14.914436 ]\n",
      " [-19.039238 ]\n",
      " [-13.2786255]\n",
      " [-14.993626 ]\n",
      " [-16.968872 ]\n",
      " [-16.157917 ]\n",
      " [-22.078262 ]\n",
      " [-27.293266 ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 12231.3759765625 \n",
      "Prediction :\n",
      "[[43.16722 ]\n",
      " [38.92281 ]\n",
      " [64.13846 ]\n",
      " [56.88572 ]\n",
      " [42.62716 ]\n",
      " [55.684196]\n",
      " [55.79019 ]\n",
      " [51.981804]\n",
      " [62.46227 ]\n",
      " [55.94705 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 5287.12353515625 \n",
      "Prediction :\n",
      "[[ 97.59089 ]\n",
      " [ 97.0528  ]\n",
      " [ 94.32073 ]\n",
      " [100.271095]\n",
      " [112.16209 ]\n",
      " [ 92.96686 ]\n",
      " [106.03886 ]\n",
      " [107.69688 ]\n",
      " [114.504074]\n",
      " [ 81.644264]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1493.1214599609375 \n",
      "Prediction :\n",
      "[[ 74.05583 ]\n",
      " [110.207405]\n",
      " [ 78.125465]\n",
      " [125.918816]\n",
      " [109.81077 ]\n",
      " [107.33984 ]\n",
      " [102.183716]\n",
      " [148.57176 ]\n",
      " [127.084   ]\n",
      " [109.535515]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 783.9134521484375 \n",
      "Prediction :\n",
      "[[155.31958]\n",
      " [134.9293 ]\n",
      " [146.63405]\n",
      " [157.76044]\n",
      " [141.21684]\n",
      " [143.87985]\n",
      " [143.15866]\n",
      " [138.45131]\n",
      " [141.47475]\n",
      " [163.08902]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 321.26666259765625 \n",
      "Prediction :\n",
      "[[144.10187 ]\n",
      " [167.50797 ]\n",
      " [168.25812 ]\n",
      " [180.46432 ]\n",
      " [128.52313 ]\n",
      " [ 89.579636]\n",
      " [132.37454 ]\n",
      " [ 94.56593 ]\n",
      " [151.71573 ]\n",
      " [133.7193  ]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 93.63523864746094 \n",
      "Prediction :\n",
      "[[134.21553]\n",
      " [128.69669]\n",
      " [183.90213]\n",
      " [156.44302]\n",
      " [137.56572]\n",
      " [175.07071]\n",
      " [150.60313]\n",
      " [165.39822]\n",
      " [176.6404 ]\n",
      " [158.10988]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 84.15319061279297 \n",
      "Prediction :\n",
      "[[164.65643]\n",
      " [163.85036]\n",
      " [158.25836]\n",
      " [159.95825]\n",
      " [185.94057]\n",
      " [152.18541]\n",
      " [177.23401]\n",
      " [177.83568]\n",
      " [190.89896]\n",
      " [135.94019]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 97.02226257324219 \n",
      "Prediction :\n",
      "[[ 96.57833 ]\n",
      " [142.3618  ]\n",
      " [101.974365]\n",
      " [163.34326 ]\n",
      " [144.50099 ]\n",
      " [138.31552 ]\n",
      " [132.7418  ]\n",
      " [189.28987 ]\n",
      " [160.91902 ]\n",
      " [141.84274 ]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 84.88082122802734 \n",
      "Prediction :\n",
      "[[182.67336]\n",
      " [156.62247]\n",
      " [172.6211 ]\n",
      " [183.89616]\n",
      " [164.60182]\n",
      " [169.27106]\n",
      " [168.44783]\n",
      " [162.65637]\n",
      " [164.0521 ]\n",
      " [191.01373]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 46.08683776855469 \n",
      "Prediction :\n",
      "[[157.71341 ]\n",
      " [184.23744 ]\n",
      " [184.53821 ]\n",
      " [198.35588 ]\n",
      " [141.24089 ]\n",
      " [ 99.24805 ]\n",
      " [145.9032  ]\n",
      " [104.774734]\n",
      " [167.63348 ]\n",
      " [148.85269 ]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 42.22486114501953 \n",
      "Prediction :\n",
      "[[157.48172 ]\n",
      " [184.32603 ]\n",
      " [184.42303 ]\n",
      " [198.39264 ]\n",
      " [141.26587 ]\n",
      " [ 99.5597  ]\n",
      " [146.06898 ]\n",
      " [105.080086]\n",
      " [167.99963 ]\n",
      " [149.58324 ]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 38.71397399902344 \n",
      "Prediction :\n",
      "[[157.26135]\n",
      " [184.40947]\n",
      " [184.31299]\n",
      " [198.42812]\n",
      " [141.2879 ]\n",
      " [ 99.85634]\n",
      " [146.22884]\n",
      " [105.37463]\n",
      " [168.34819]\n",
      " [150.28056]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 35.52267837524414 \n",
      "Prediction :\n",
      "[[157.05173]\n",
      " [184.48792]\n",
      " [184.20781]\n",
      " [198.4623 ]\n",
      " [141.30716]\n",
      " [100.13865]\n",
      " [146.38295]\n",
      " [105.65878]\n",
      " [168.67989]\n",
      " [150.94615]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 32.62226104736328 \n",
      "Prediction :\n",
      "[[156.85242]\n",
      " [184.56166]\n",
      " [184.10733]\n",
      " [198.49529]\n",
      " [141.32378]\n",
      " [100.40732]\n",
      " [146.53159]\n",
      " [105.93295]\n",
      " [168.99554]\n",
      " [151.5814 ]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 29.986358642578125 \n",
      "Prediction :\n",
      "[[156.66289 ]\n",
      " [184.63098 ]\n",
      " [184.0113  ]\n",
      " [198.52711 ]\n",
      " [141.33795 ]\n",
      " [100.662994]\n",
      " [146.67491 ]\n",
      " [106.19752 ]\n",
      " [169.29591 ]\n",
      " [152.18773 ]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 27.591115951538086 \n",
      "Prediction :\n",
      "[[156.4827 ]\n",
      " [184.6961 ]\n",
      " [183.91959]\n",
      " [198.55785]\n",
      " [141.34982]\n",
      " [100.90625]\n",
      " [146.81319]\n",
      " [106.45282]\n",
      " [169.58174]\n",
      " [152.76643]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 25.414907455444336 \n",
      "Prediction :\n",
      "[[156.31139 ]\n",
      " [184.75716 ]\n",
      " [183.83192 ]\n",
      " [198.58748 ]\n",
      " [141.35953 ]\n",
      " [101.13767 ]\n",
      " [146.94655 ]\n",
      " [106.699234]\n",
      " [169.85362 ]\n",
      " [153.31873 ]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 23.437908172607422 \n",
      "Prediction :\n",
      "[[156.14856]\n",
      " [184.81442]\n",
      " [183.74815]\n",
      " [198.61607]\n",
      " [141.36722]\n",
      " [101.35782]\n",
      " [147.07523]\n",
      " [106.93707]\n",
      " [170.11226]\n",
      " [153.84581]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 21.642086029052734 \n",
      "Prediction :\n",
      "[[155.9938 ]\n",
      " [184.86809]\n",
      " [183.6681 ]\n",
      " [198.64368]\n",
      " [141.373  ]\n",
      " [101.56723]\n",
      " [147.19934]\n",
      " [107.16668]\n",
      " [170.35826]\n",
      " [154.34883]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 20.010927200317383 \n",
      "Prediction :\n",
      "[[155.84676]\n",
      " [184.91835]\n",
      " [183.59161]\n",
      " [198.67033]\n",
      " [141.37703]\n",
      " [101.76639]\n",
      " [147.31915]\n",
      " [107.38835]\n",
      " [170.59224]\n",
      " [154.82893]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 18.529760360717773 \n",
      "Prediction :\n",
      "[[155.70702]\n",
      " [184.96535]\n",
      " [183.51852]\n",
      " [198.69603]\n",
      " [141.37938]\n",
      " [101.95578]\n",
      " [147.43474]\n",
      " [107.60239]\n",
      " [170.81471]\n",
      " [155.28703]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 17.184749603271484 \n",
      "Prediction :\n",
      "[[155.5743  ]\n",
      " [185.0093  ]\n",
      " [183.44867 ]\n",
      " [198.72089 ]\n",
      " [141.38022 ]\n",
      " [102.13587 ]\n",
      " [147.54633 ]\n",
      " [107.809074]\n",
      " [171.02628 ]\n",
      " [155.72426 ]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 15.9636812210083 \n",
      "Prediction :\n",
      "[[155.44821 ]\n",
      " [185.05032 ]\n",
      " [183.38196 ]\n",
      " [198.74486 ]\n",
      " [141.37961 ]\n",
      " [102.307076]\n",
      " [147.65402 ]\n",
      " [108.00868 ]\n",
      " [171.22742 ]\n",
      " [156.14148 ]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 14.85528564453125 \n",
      "Prediction :\n",
      "[[155.32848]\n",
      " [185.08858]\n",
      " [183.31816]\n",
      " [198.76802]\n",
      " [141.37764]\n",
      " [102.46984]\n",
      " [147.758  ]\n",
      " [108.20149]\n",
      " [171.4186 ]\n",
      " [156.5396 ]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 13.849363327026367 \n",
      "Prediction :\n",
      "[[155.21475]\n",
      " [185.12424]\n",
      " [183.25722]\n",
      " [198.79037]\n",
      " [141.37442]\n",
      " [102.62454]\n",
      " [147.85834]\n",
      " [108.38772]\n",
      " [171.60033]\n",
      " [156.91946]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 12.936506271362305 \n",
      "Prediction :\n",
      "[[155.10683]\n",
      " [185.15741]\n",
      " [183.19897]\n",
      " [198.81198]\n",
      " [141.37007]\n",
      " [102.77155]\n",
      " [147.95526]\n",
      " [108.56765]\n",
      " [171.77301]\n",
      " [157.28197]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 12.10828685760498 \n",
      "Prediction :\n",
      "[[155.00436]\n",
      " [185.18828]\n",
      " [183.14334]\n",
      " [198.83286]\n",
      " [141.36464]\n",
      " [102.91126]\n",
      " [148.04887]\n",
      " [108.74147]\n",
      " [171.93715]\n",
      " [157.62787]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 11.357019424438477 \n",
      "Prediction :\n",
      "[[154.9071 ]\n",
      " [185.21689]\n",
      " [183.09013]\n",
      " [198.853  ]\n",
      " [141.3582 ]\n",
      " [103.04401]\n",
      " [148.13925]\n",
      " [108.90945]\n",
      " [172.09303]\n",
      " [157.95787]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 10.675638198852539 \n",
      "Prediction :\n",
      "[[154.81482]\n",
      " [185.24344]\n",
      " [183.03932]\n",
      " [198.87248]\n",
      " [141.35086]\n",
      " [103.1701 ]\n",
      " [148.22656]\n",
      " [109.07177]\n",
      " [172.24115]\n",
      " [158.27277]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "Step_val = []\n",
    "Cost_val = []\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    \n",
    "\n",
    "    Step_val.append(step)\n",
    "    Cost_val.append(cost_val)\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12,6]\n",
    "\n",
    "# Show the cost function\n",
    "plt.plot(Step_val, Cost_val)\n",
    "plt.title('cost function')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('cost')\n",
    "plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[180.75388]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score\n",
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[155.70259]\n",
      " [185.67662]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score many\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
